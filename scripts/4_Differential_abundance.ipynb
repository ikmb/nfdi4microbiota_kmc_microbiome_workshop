{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dd7d5a66",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Differential abundance analysis\"\n",
    "author: \"Eike Matthias Wacker (e.wacker@ikmb.uni-kiel.de)\" \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a9d78",
   "metadata": {},
   "source": [
    "This tutorial can be executed with the kernel 'kmc_workshop' directly in the code-cells of this jupyter-notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b23a3",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The aim of this tutorial is to give you an insight into possible ways how to perform differential abaundance analysis of microbiome amplicon data.\n",
    "\n",
    "\n",
    "We continue to work with earlier processed GMBC dataset. To remind you, this is a dataset consisting of 16S rRNA V3-V4 amplicon data from human fecal samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbdb1fd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "getwd()\n",
    "# \"~/KMC_workshop/scripts\"\n",
    "#setwd(\"~/KMC_workshop/scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe5cae",
   "metadata": {},
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "For this tutorial we will stick with R packages, that you worked with earlier plus some new, that we later use for the differential abundance analysis.\n",
    "\n",
    "Following packes are added:\n",
    "* DESeq2: DESeq2 is a framework designed for the analysis of differential expression analysis of RNASeq data. RNASeq data and microbiome amplicon data share many properties regarding their general structure, which enables us to repurpose DESeq2 for the analysis of microbiome data.\n",
    "* Maaslin2: Maaslin2 (Microbiome Multivariable Association with Linear Models 2) is a package for the the efficient determination of multivaribale associations between (clinical) metadata and microbial meta-omics features. It does so by applying general linear models with a multitude of filtering, normalization and tranformations methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626bd07",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(phyloseq)\n",
    "library(vegan)\n",
    "library(microbiome)\n",
    "library(DESeq2)\n",
    "library(Maaslin2)\n",
    "library(EnhancedVolcano)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6938d",
   "metadata": {},
   "source": [
    "# Import and format the data\n",
    "The dataset we are using was pre-processed using the DADA2 workflow.\n",
    "\n",
    "Let's import the data so, so we can start with the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d74c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "path <- \"~/kmc_workshop/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb857e76",
   "metadata": {},
   "source": [
    "We load here the full gmbc-phyloseq object, so you can also play with other country combinations if you want, additionally the count data is still \"raw\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70dbde",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(paste0(path,'R_objects/full_phyloseq_object.RData'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f75451",
   "metadata": {},
   "source": [
    "# The phyloseq object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb717515",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a94f59",
   "metadata": {},
   "source": [
    "The dataset that we are using is called 'ps'. It should look the same as in the previous tutorial sessions. If this is not the case, please inform one of the supervisors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aeb3ca",
   "metadata": {},
   "source": [
    "Note: Here we are using %>% (pipe) from the magrittr package which is part of the tidyverse. It is much easier to code with it. \"(With it, you) ... may pipe a value forward into an expression or function call; something along the lines of x %>% f, rather than f(x).\" You will see the pipe alot in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce1d92",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ps %>% \n",
    "    sample_data() %>% \n",
    "    pull(country) %>% \n",
    "    unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fce773",
   "metadata": {},
   "source": [
    "> **Tip**\n",
    "To understand better what is going on, try to run each line removing the \"%>%\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c71d3d",
   "metadata": {},
   "source": [
    "If the loaded phyloseq object should still contain several countries, for example because you have loaded the total-cohort phyloseq object instead of your previously prepared one, then use the lower cell to restrict the object to samples from only two countries of your choice. Please choose a country combination that contains both the lifestyle categories “lifestyle_industrialized” and “lifestyle_non_industrialized”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73b978",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ps %>% \n",
    "    sample_data() %>% \n",
    "    data.frame() %>% \n",
    "    select(country, lifestyle) %>% \n",
    "    table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff902a",
   "metadata": {},
   "source": [
    "In this case, you can execute the function here to restrict the phylseq object to your selected countries. If the object already contains only the country combination of samples, we copy the phyloseq object “ps” as “subset.ps”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ed9bf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#subset.ps <- subset_samples(ps, country %in% c(\"Tanzania\", \"UnitedStates\")) # Execute this, if you need to subset your phyloseq object\n",
    "subset.ps <- subset_samples(ps, country %in% c(\"Malaysia\", \"Finland\"))\n",
    "\n",
    "#subset.ps <- ps # Execute this if your object is already a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3804483",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "subset.ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a67bb",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Now we can start with the analysis part. We should first have a glimpse what the data looks like. For this purpose, we will make some plots of the raw abundance counts.\n",
    "\n",
    "This is an important step to check for quality issues in the data. Some samples might only contain a single taxa or contain very low counts. Maybe we need to remove some samples due to poor quality.\n",
    "\n",
    "First, let's check that we have sufficient counts in every sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01bb48",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "counts <-\n",
    "  subset.ps %>% \n",
    "  otu_table() %>%\n",
    "  colSums()\n",
    "counts %>% data.frame(counts=.) %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c1c8f",
   "metadata": {},
   "source": [
    "In our case we would like to have more than 8 thousand counts per samples.\n",
    "\n",
    "Can you identify samples with too few counts? If so, one might need to exclude this sample from further analysis. If many samples show low count numbers, something else might be off and one should investigate these issues before continuing with the analysis.\n",
    "\n",
    "We can also use ggplot2 to visualise the counts per sample. With a horizontal line as a minimum threshold and a conditional coloration it can be easily used to show outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37445864",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "to.plot <-\n",
    "  counts %>% \n",
    "  data.frame(counts = ., Sample = names(.))\n",
    "ggplot(to.plot, aes(x = Sample, y = counts, fill = counts > 8000)) +\n",
    "  geom_col() +\n",
    "  geom_hline(yintercept = 8000) + # add horizontal line \n",
    "  scale_fill_manual(values = c(\"TRUE\" = \"darkgrey\", \"FALSE\" = \"purple\")) + # color low counts purple\n",
    "  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) # flip the axis names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2fc70",
   "metadata": {},
   "source": [
    "To get the sample names with poor quality directly, we can filter the abdundance table directly and then display the row-names. Should we want to remove samples we can do this with the function commented out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d623c0",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bad_quality <- to.plot[counts < 8000,] %>% rownames()\n",
    "bad_quality\n",
    "\n",
    "#subset.ps <- subset_samples(subset.ps, !(sample_names(subset.ps) %in% bad_quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7cd8a",
   "metadata": {},
   "source": [
    "## Recap: Taxonomy\n",
    "\n",
    "Here, we are going to look at the microbiome at the taxonomical perspective. To remember: we produced amplicon variant sequences (ASVs) using DADA2 and these were classified into different taxonomic levels.\n",
    "\n",
    "\n",
    "![](../assets/Taxonomic_Rank_Graph.png)\n",
    "Taoxnomic levels. Author: Annina Breen.\n",
    "\n",
    "The assignment of taxonomic labels to the final ASV sequences is an important step, as these information can help make sense of the results for example by knowing that specific bacteria can perform specific metabolic functions. Also, taxonomic labels help to bin sequences together into larger phylogenetically related groups (meaning: groups that have a common ancestor at a given level of similarity), for example belonging to the same bacterial Phylum (very broad), Family (kind of similar), or even species or strain (very similar; many functions/genes are shared). As already mentioned, databases are still growing and newly discovered bacteria are constantly added to them, especially now as large-scale sequencing is widely available. This makes it especially hard to keep them up to date. Luckily, today we are working with samples from human stool samples, an environment which is widely studied and thus key members of the community are rather well-known and described.  \n",
    "\n",
    "So, lets have a look at the taxonomic composition of the stool microbiome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede0c7a",
   "metadata": {},
   "source": [
    "> **Tip**\n",
    "To understand better what is going on, try to run each line removing the \"%>%\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cbe306",
   "metadata": {},
   "source": [
    "## Set a taxonomic level for your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3110d82",
   "metadata": {},
   "source": [
    "For all the following Visualizations and Analysis we can set the taxonomic level in a single variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d484964",
   "metadata": {},
   "source": [
    "We will start with Phylum level but can later change this to other levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50492751",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "taxonomic_level = \"Family\"\n",
    "paste(\"We are using the taxonomic level\", taxonomic_level, \"for our analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec28423",
   "metadata": {},
   "source": [
    "We will use this variable again and again in the further steps so that the outputs are all comparable with each other. Of course, you always have the option of replacing the variable with a string with a valid taxonomic level name e.g. 'Phylum', 'Order' or 'Genus'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a706144",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Phyloseq offers a function to directly plot the taxonomic composition. This function is a so-called wrapper, i.e. it combines many different functions to simplify our lives. The output of this function is a ggplot object and can therefore be handled in exactly the same way as we did in the previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24333b",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 16, repr.plot.height = 12, repr.plot.res = 100) #Set the plot size\n",
    "\n",
    "plot_bar(subset.ps, x=\"Sample\", fill=taxonomic_level) +  \n",
    "    facet_grid(~ country, scales = \"free_x\",space=\"free\") +# divide the plot into facets \n",
    "    theme(legend.position=\"none\") # position of the legend in the plot, to remove legend use 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e92e9",
   "metadata": {},
   "source": [
    "We see that samples have different sequence counts. Each ASV is a subdivision of the plot. Can you already spot phyla that differ between the two groups?\n",
    "\n",
    "\n",
    "\n",
    "**How can we improve here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720d602",
   "metadata": {},
   "source": [
    "Due to the different counts in each sample, it is quite difficult to say whether a certain taxa is more common in one group than in others, so the abundance can be relativized here so that all samples have the same total number of counts. This can be achieved by converting our abundance dataframe from absolute to relative counts (the in total 100 counts equal 100 percent), but we can also simply use rarefying, both options lead to the desired result.\n",
    "\n",
    "In this case, we will use a rarefying procedure to reduce all counts for every sample to the minimum counts number we have in our dataset. This is why it is important to remove samples with low quality prior to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbaaa1",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 16, repr.plot.height = 12, repr.plot.res = 100) #Set the plot size\n",
    "\n",
    "subset.ps %>% \n",
    "  aggregate_taxa(level = taxonomic_level) %>% # aggregate all ASVs into the level phyloum\n",
    "  rarefy_even_depth(rngseed = 123) %>% # make all samples with the same sequencing depth using rarefaction\n",
    "  plot_bar(x=\"Sample\", fill=taxonomic_level) +  \n",
    "    facet_grid(~ country, scales = \"free_x\", space=\"free\") + # divide the plot into facets \n",
    "    theme(legend.position=\"none\") # remove legend from plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12364d",
   "metadata": {},
   "source": [
    "As you can see, we have quite a few different taxa in our plot. The colors differ only marginally when plotting dozents of unique taxa and you can hardly distinguish the taxa.\n",
    "\n",
    "To keep a plot clearly arranged, we can also plot only the most abundant taxa by using the 'aggregate_top_taxa' function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e3996",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Original function was deprecated. So we keep a backup here:\n",
    "aggregate_top_taxa2 <- function(x, top, level) {\n",
    "  x <- aggregate_taxa(x, level)\n",
    "  tops <- top_taxa(x, top)\n",
    "  tax <- tax_table(x)\n",
    "  inds <- which(!rownames(tax) %in% tops)\n",
    "  tax[inds, level] <- \"Other\"\n",
    "  tax_table(x) <- tax\n",
    "  tt <- tax_table(x)[, level]\n",
    "  tax_table(x) <- tax_table(tt)\n",
    "  aggregate_taxa(x, level)\n",
    "}\n",
    "subset.ps %>% \n",
    "    aggregate_top_taxa2(top = 10, level = taxonomic_level) %>% # Here we used the function from the package microbiome to reduce the number of taxa to the top 10. The rest is lumped into the category \"other\"\n",
    "    rarefy_even_depth(rngseed = 123) %>% \n",
    "    plot_bar(x=\"Sample\", fill=taxonomic_level) +\n",
    "    facet_grid(~ country, scales = \"free\", space='free') + \n",
    "    scale_fill_brewer(palette=\"Set3\") # change colors of bars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e32b03f",
   "metadata": {},
   "source": [
    "It is also recommended to use a different color palette than the standard one. In the plot above we have used a color palette from ColorBrewer with the function scale_fill_brewer(palette=\"Set3\")\n",
    "\n",
    "**TASK: Try out other color palettes as well!**\n",
    "\n",
    "There are many more color palettes to choose from, with the following command you can see all the options directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90011995",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "RColorBrewer::display.brewer.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec333ae",
   "metadata": {},
   "source": [
    "**TASK, if you have spare time:** The color palettes shown can only be used with a maximum of 13 values shown. Find out if you can create your own color palette that you can use to visualize results with more values. Remember that your color palette must also be suitable for colorblind people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc289641",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run your own code here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1ba43",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK: Try with other levels!** \n",
    "\n",
    "If you do know which levels there are: check the columns of tax_table(ps)@.Data using the function colnames() It's possible that we can actually identify differences between the groups also on genus level \"by eye\". \n",
    "Additionally, check the internet, if there is a direct function that will return the taxonomic levels in your phyloseq object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e6830",
   "metadata": {
    "scrolled": true,
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#The options in our phyloseq objects are:\n",
    "tax_table(subset.ps)@.Data %>% colnames()\n",
    "# #Phyloseq function, returning the taxonomic ranks in a phyloseq object:\n",
    "#rank_names(subset.ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a964a",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run your own code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f62b8",
   "metadata": {},
   "source": [
    "**But how do we know whether it is this significant?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f21ae7",
   "metadata": {},
   "source": [
    "# Statistical differential abundance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f043b",
   "metadata": {},
   "source": [
    "There are many ways how to perform statistical testing with the abundance table and metadata. We can start with a simple Wilcoxon test. Later, we will also use some more advanced tools to identify significant differential abundant taxa in our dataset.\n",
    "\n",
    "There are many specialized tools out there which you can use to perform differential abundance testing in microbiome data. For further reading I can recommend this [Paper](https://www.nature.com/articles/s41467-022-28034-z), which compares lots more tools than we can do today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852219c4",
   "metadata": {},
   "source": [
    "## Data normalization & transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b882e1",
   "metadata": {},
   "source": [
    "First of all, we should make sure that our phyloseq object is clean. If several rows suddenly describe the same species during preprocessing, we combine them in the following step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5100d8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "glom.ps <- tax_glom(subset.ps, \"Species\") # Agglomerate taxa of the same type, this might take a moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634f978",
   "metadata": {},
   "source": [
    "We also set new taxa names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d653f8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "full_tax_names <- apply(tax_table(glom.ps), 1, function(x) paste(x, collapse = \";\"))\n",
    "head(full_tax_names)\n",
    "taxa_names(glom.ps) <- full_tax_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606e2e1",
   "metadata": {},
   "source": [
    "Then we will take another look at the newly created phyloseq object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da564d26",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "glom.ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6abb1",
   "metadata": {},
   "source": [
    "We also look at how many taxa we have when we aggretgate our phyloseq object to our chosen taxonomic level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cbad2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "glom.ps %>% aggregate_taxa(level = taxonomic_level) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0544c",
   "metadata": {},
   "source": [
    "Depending on the level selected, we will certainly have a number of taxa that are very rare. These can subsequently be disruptive, as we can only perform meaningful statistics to a limited extent in rare taxa and there is always the possibility that these could also be artifacts. For the sake of simplicity, we will remove these from our dataset using the following functions. In this case, our filter is that we want to have at least 5 counts in at least 20 percent of the available samples. But this is of course highly customizable to the given study design and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea5426",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "filter <- glom.ps %>% \n",
    "                 aggregate_taxa(level = taxonomic_level) %>% \n",
    "                 phyloseq::genefilter_sample(., filterfun_sample(function(x) x >= 5), \n",
    "                                       A = 0.2*nsamples(glom.ps))\n",
    "ps_filtered <- prune_taxa(filter, glom.ps %>% aggregate_taxa(level = taxonomic_level))\n",
    "ps_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634d1e6",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK** Could you think of a more suitable filter, as the individual samples in our dataset might have different sums of abundance counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8dd2d2",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "In our case, we are currently using the non-rarefied data set. All samples have a different number of counts. To take this into account, we would have to transform our data so that the sample counts are relative. One function to do this would be the function 'transform_sample_counts'. The filter can then also be applied to the absolute count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8fc51",
   "metadata": {
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "better_filter <- glom.ps %>% \n",
    "    aggregate_taxa(level = taxonomic_level) %>% \n",
    "    transform_sample_counts(., function(x) x / sum(x) ) %>%\n",
    "    phyloseq::genefilter_sample(., filterfun_sample(function(x) x >= 5), \n",
    "                                       A = 0.2*nsamples(glom.ps))\n",
    "\n",
    "ps_filtered <- prune_taxa(better_filter, glom.ps %>% aggregate_taxa(level = taxonomic_level))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83785ee",
   "metadata": {},
   "source": [
    "### CLR-Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab990d33",
   "metadata": {},
   "source": [
    "For some steps, in this case simple statistical tests, its useful not to work with the raw counts itself. In these cases we apply a transformation to reduce outlier spreading as well as remove variance introduced in the data collection and measurement process (Batch effects). We apply centered log-ratio transformation (CLR) to our data. With that we adress the fact, that 16S data quantify relative, rather than absolute, abundance of the microbiome.\n",
    "\n",
    "The CLR transformation has two useful features: First it normalizes compositional data so that samples representing the same relative abundances are equated. Secondly it converts multiplicative relationships between the relative abundances into linear relationships – a feature which allows statistical models to represent fold-differences. This is especially useful when applying maschine learning methods, but this would go beyond the scope of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f1449",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# How our counttable looks currently:\n",
    "ps_filtered %>% \n",
    "    otu_table() %>% \n",
    "    head()\n",
    "\n",
    "# Apply a transformation on the counttable, in this case centered log ratio transformation:\n",
    "transf.ps <- ps_filtered %>% \n",
    "                microbiome::transform(., transform='clr') %>% \n",
    "                otu_table()\n",
    "\n",
    "# How our counttable looks after applied transformation:\n",
    "transf.ps %>% \n",
    "    otu_table() %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8f7ce",
   "metadata": {},
   "source": [
    "If we plot the distributions in the raw state compared to the CLR transformation, we can see how outliers are now less far from the rest of the distribution.\n",
    "\n",
    "Don't be afraid of this complicated looking cell below, there are probably easier ways how to quickly inspect the differences, but this one here works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f8110",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "taxa_to_inspect <- rownames(ps_filtered %>% otu_table())[3] # Select a single taxa\n",
    "\n",
    "ps_filtered %>% \n",
    "  otu_table() %>% # extract otu table\n",
    "  as.data.frame() %>% # make it a data frame\n",
    "  rownames_to_column(\"taxa\") %>% # rownames are added as column named taxa\n",
    "  pivot_longer(cols = c(-taxa), names_to = \"sample_id\") %>% # make the table to a long three column table, containing the columns taxa, sample_id  and value\n",
    "  mutate(type=\"rawreads\") %>% # add a column labeling all rows as \"rawreads\"\n",
    "  rbind( transf.ps %>%  # bind to that the clr transformed dataset, we repeat all the previous functions on this, too\n",
    "           otu_table() %>% \n",
    "           as.data.frame() %>%\n",
    "           rownames_to_column(\"taxa\") %>%\n",
    "           pivot_longer(cols = c(-taxa), names_to = \"sample_id\") %>%\n",
    "           mutate(type=\"clr\") ) %>% # add a column labeling all rows of this dataset as \"clr\"\n",
    "  filter(taxa == taxa_to_inspect) %>% # we filter the data to only contain our chosen taxa\n",
    "  ggplot() +\n",
    "  geom_histogram(aes(x = value), bins = 50) + #plot a histogram\n",
    "  ylab(paste0(\"Counts for \",taxa_to_inspect ))+\n",
    "  facet_grid( ~type, scales=\"free\") + # split the plot by the column type\n",
    "  theme(text = element_text(size=20)) # increase textsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66af89d",
   "metadata": {},
   "source": [
    "**TASK** Try to plot some other taxa by changing the number in the first line!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e7d0e",
   "metadata": {},
   "source": [
    "## Wilcoxon's Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dd5a9",
   "metadata": {},
   "source": [
    "The transformed data is now well suited for statistical tests. We assume that our abundance counts are not normally distributed, so we use the non-parametric Wilcoxon test instead of the popular t-test.\n",
    "\n",
    "We are working outside the phyloseqs object here, so we create a table that contains both counts and our phenotype to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35b567",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "transf.df <- transf.ps %>% \n",
    "    otu_table() %>% \n",
    "    t() %>% # transpose the otu_table\n",
    "    as.data.frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea952d26",
   "metadata": {},
   "source": [
    "Add the metadata column to the table for which to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835c0c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tansf.df <- transf.df %>%\n",
    "                mutate(grouping=sample_data(ps_filtered)$country)\n",
    "\n",
    "tansf.df %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542e66b",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve countries\n",
    "chosen_countries <- tansf.df$grouping %>% unique()\n",
    "chosen_countries\n",
    "\n",
    "#apply wilcox test to clr transformed table\n",
    "\n",
    "wilcox_clr <- tansf.df %>%\n",
    "    rownames_to_column(\"sample_id\")%>%\n",
    "    pivot_longer(cols = c(-sample_id,-grouping), names_to = \"taxa\", values_to = \"abundance\") %>%\n",
    "    group_by(taxa) %>%\n",
    "    summarize(\n",
    "        p_value = wilcox.test(abundance[grouping == chosen_countries[1]], \n",
    "                              abundance[grouping == chosen_countries[2]])$p.value,\n",
    "        countryone_mean=mean(abundance[grouping == chosen_countries[1]]),\n",
    "        countrytwo_mean=mean(abundance[grouping == chosen_countries[2]])\n",
    "    ) %>%\n",
    "  # Adjust p-values with Bonferroni correction\n",
    "  mutate(p_adj = p.adjust(p_value, method = \"bonferroni\"), .before = countryone_mean)\n",
    "\n",
    "wilcox_clr %>% \n",
    "    arrange(p_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431224d",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK** What would you need to change to test other metadata features? Use lifestyle as phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d715f",
   "metadata": {
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tansf.df <- transf.df %>%\n",
    "                mutate(grouping=sample_data(ps_filtered)$lifestyle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72905601",
   "metadata": {},
   "source": [
    "**TASK** Why do we need to apply p-value adjustment to our results? Search the internet if you don't know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d859a",
   "metadata": {},
   "source": [
    "## DESeq2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16aebb8",
   "metadata": {},
   "source": [
    "We will use DESeq2 package to apply a generalized linear model with negative binomial distribution to the bacterial abundances - in our default case here, on the Phylum level. Within DESeq2, we will apply Wald test to see whether the abundance of taxa differs between the groups. DESeq2 includes an internal calculation for library size to account for different sequencing depths and also performs P value adjustments for multiple tests. This means that all we have to do is use the raw abundance dataset with the metadata as input. There is no need for normalization and transformation here.\n",
    "\n",
    "The theory behind DESeq2 is quite complex. If you want to dive deeper, have a look into the [DESeq2 Vignette](https://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#theory). As DESeq2 is a tool developed for RNA-seq the explanation uses the vocabulary of gene expression: In short, DESeq2 uses a generalized linear model with negative binomial distribution to model the counts. For this the counts are normalized based on a per gene (for our case: taxa) normalization factor and dispersion. The model coefficients are estimated for each sample group along with their standard error and result in log2 foldchanges for each gene for each sample group.\n",
    "Then the Wald test will be used. The null hypthesis for every gene is that the expression foldchanges between two groups is equal to 0. The Wald test uses the log2foldchanges and divides those by their standard errors. This results in z-statistics. Next, the z-statistic is compared to a standard normal distribution, and a p-value is computed reporting the probability that a z-statistic at least as extreme as the observed value would be found at random.\n",
    "If the returned p-value is small we can reject the null hypothesis, which means that we see differential gene expression (differential abundance) in our data.\n",
    "\n",
    "Multiple testing correction will automatically be performed by DESeq2.\n",
    "We already used Bonferroni correction, where we adjust the p-values with: \n",
    "> p-adj = p-value * m (total number of tests) \n",
    "\n",
    "It is very conversative, which means we report highly likely false negatives. But on the other hand, it's very easy to calculate.\n",
    "\n",
    "DESeq2 uses by default Benjamini-Hochberg or False Discovery Rate. As it is named, it tries to control the rate of type I errors in the null hypothesis. The p-values are collected, sorted in order from smallest du largest, so every p-value has a defined rank. It then calculates:  \n",
    ">    p-adj = (m / rank of p-value) * p-value \n",
    "\n",
    "This means, that with a selected FDR threshold of usually q=p-adj=0.05, our reported results are expected to contain 5% false positives.\n",
    "\n",
    "Now to the practical part:\n",
    "\n",
    "First, we need to format the data by combining all ASV counts into the chosen taxonomic level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86059828",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ps.to.dseq <-\n",
    "  ps_filtered %>%\n",
    "  aggregate_taxa(level = taxonomic_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3345b",
   "metadata": {},
   "source": [
    "Now, let us do the DESeq2 routine. Luckily the phyloseq package contains functions to create the necessary DESeq object directly from the phyloseq object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670515ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DESeq2 object from \n",
    "dseq <-\n",
    "  ps.to.dseq %>% \n",
    "  phyloseq_to_deseq2(design = ~ sex + lifestyle)\n",
    "# Perform test. There is a lot going under the hood here, including: estimation of size factors, estimation of dispersion, and Negative Binomial GLM fitting and Wald statistics.\n",
    "res <-\n",
    "  DESeq(dseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8d36b",
   "metadata": {},
   "source": [
    "With DESeq2, it should be said that the design is only tested for the last variable. All the variables mentioned before in the design formula are used as covariates. The variable to be tested must be categorical. In R this is referred to as a factor. The last level as a factor is compared with the reference level by default. For other comparisons, the contrast must be specified in the “contrast” parameter of the “result” function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c997a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the result table\n",
    "res.df <-\n",
    "  res %>% \n",
    "  results(tidy = T, contrast = c(\"lifestyle\",\"lifestyle_non_industrialized\",\"lifestyle_industrialized\"))\n",
    "#Visualize what we got out of it\n",
    "res.df %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2c774",
   "metadata": {},
   "source": [
    "That's it! You can have a look at the `res.df` table and you will find the results of all the taxa tested. Depending on your question, you can perform similar analysis to all levels, from phylum to ASV (species level). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1ec57",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter and format to plot\n",
    "res.df.to.plot <-\n",
    "  res.df %>% \n",
    "  filter(padj < 0.05) %>% # keep only results with adjusted P value less than 0.05\n",
    "  mutate(Taxa = row) %>% # Create Taxa column\n",
    "  #left_join(tax_table(ps.to.dseq )@.Data %>% data.frame()), by = \"Taxa\")# %>% # Add taxonomy information from the phyloseq object.\n",
    "  ## Arrange the data for a prettier plot\n",
    "  arrange(log2FoldChange) %>% \n",
    "  mutate(Taxa = factor(Taxa, levels = Taxa %>% unique()))\n",
    "head(res.df.to.plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9b40f",
   "metadata": {},
   "source": [
    "We will later format this table and visualize the data using ggplot2. But before we do that, let's take a look at another tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b15138",
   "metadata": {},
   "source": [
    "**TASK** What do you need to change to test for significant abundance changes between nationalities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f21fc",
   "metadata": {},
   "source": [
    "## MaAsLin2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aeca82",
   "metadata": {},
   "source": [
    "MaAsLin2 is the second generation of MaAsLin (Microbiome Multivariable Association with Linear Models). It relies on general linear models to handle most modern epidemiological study designs.\n",
    "\n",
    "A simple linear regression looks like this:\n",
    "> y = βX + ε\n",
    "\n",
    "Where y is the observed value, X the design matrix, β the regression coefficients and ε the error term. While fitting a regression, β is estimated in a way that ε is minimized.\n",
    "\n",
    "A linear mixed model is slightly more complicated and looks like this:\n",
    "\n",
    "> y = βX + Zu + ε\n",
    "\n",
    "β is a vector for fixed effects and X the associated matrix with fixed effects, while Z is a matrix for random effects with u being a vector for the random effects. The sum of the vector u equals 0.\n",
    "\n",
    "So what are fixed and random effects? As fixed effects we describe our factors that are of our primary interest, as we want to test them, whether they have an effect on the abundance of the microbiome. A random effect is an (unmeasured) effect that introduces statistical variability to our model, but we aknowledge their presence and want to account for this. In longitudinal study designs, where you have multiple samples from the sampe participant you can account for the variability of the microbiome within the same study participant with a random effect.\n",
    "\n",
    "\n",
    "Unlike DESeq2, there is no wrapper function to use the phyloseq object directly as an input. But it's not hard to put our abdundance table and metadata into the right format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18409e",
   "metadata": {},
   "source": [
    "To prepare the inputs for MaAsLin2, we just have to prepare the abundance table in a chosen taxonomic level and the metadata dataframe. MaAsLin2 will take of transformation and filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c47b4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ps.to.maaslin <- ps_filtered %>%\n",
    "  aggregate_taxa(level = taxonomic_level)\n",
    "\n",
    "df_input_data <-\n",
    "    ps.to.maaslin %>% \n",
    "    otu_table() %>% \n",
    "    as(\"matrix\") %>% \n",
    "    round(digits = 0)\n",
    "\n",
    "df_input_data[1:5, 1:5]\n",
    "\n",
    "df_input_metadata <- \n",
    "    ps.to.maaslin %>% \n",
    "    sample_data() %>%\n",
    "    data.frame()\n",
    "\n",
    "df_input_metadata[1:5, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2e332",
   "metadata": {},
   "source": [
    "In the parameter fixed_effects you can pass all variables you want to test. The tool is ordering the categories in alphabetical order, where the first category is treated as the reference, a second option is to make it a factor with specified level order. We are using a third option here and declare the reference directly in the parameter 'reference'. Covariates can be passed along to the parameter 'random_effects' that you want to control for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcb566",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit_data = Maaslin2(\n",
    "    input_data = df_input_data, \n",
    "    input_metadata = df_input_metadata, \n",
    "    output = \"../maaslin2_output\", \n",
    "    fixed_effects = c(\"lifestyle\"), # The phenotypes that you want to analyse\n",
    "    random_effects = c(), # Include random effects that you want to adjust for, e.g. sample IDs when you have longitudinal study\n",
    "    transform = \"NONE\", # Possible transformation choices:  LOG, LOGIT, AST, NONE \n",
    "    normalization= 'TSS', # Choices: TSS, CLR, CSS, NONE, TMM\n",
    "    reference = 'lifestyle,lifestyle_non_industrialized',\n",
    "    standardize = FALSE,\n",
    "    plot_heatmap = F, \n",
    "    plot_scatter = T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377b321",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit_data$results  <- fit_data$results %>% mutate(feature = gsub(\"^X.\",\"\",feature)) # Remove some artifacts from the column feature\n",
    "fit_data$results %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b64de3",
   "metadata": {},
   "source": [
    "The column qval is synonymous with p_adj. It is the output column for multiple testing corrected p-values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3942da",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "\n",
    "Let's move on to the part where we want to visualize our tabular results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a279f",
   "metadata": {},
   "source": [
    "## Wilcoxon\n",
    "\n",
    "The Wilcoxon test provides us with results comparing two groups with each other. It is therefore easy to plot the abundance of both groups and then use the p-value to make a statement about the significance of the differential abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04530af5",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 12, repr.plot.res = 100) #Set the plot size\n",
    "\n",
    "mostsign_clr <- wilcox_clr %>%\n",
    "                    arrange(p_adj) %>%\n",
    "                    pull(taxa) %>% # Store the name of most significant taxa\n",
    "                    .[1] # Take the first value\n",
    "mostsign_clr\n",
    "\n",
    "\n",
    "ps_filtered %>% \n",
    "    otu_table() %>% \n",
    "    t() %>% # transpose the otu_table\n",
    "    as.data.frame() %>%\n",
    "    mutate(grouping=sample_data(ps_filtered)$country) %>% #add country column to our dataframe\n",
    "    select(counts=matches(mostsign_clr), \"grouping\") %>% #replace mostsign_rare with a taxa you would like to plot\n",
    "    ggplot(.,aes(x=grouping, y=counts, fill=grouping))+\n",
    "    geom_boxplot()+ #make a simple boxplot\n",
    "    geom_jitter()+ #add jittered points to the plots\n",
    "    #stat_compare_means(method = \"wilcox.test\")+\n",
    "    theme(text = element_text(size=28))+ # increase text size\n",
    "    ylab(paste0(\"Abundance of \", mostsign_clr )) + #Add y axis label\n",
    "    xlab(element_blank())+ #Keep x axis label blank\n",
    "    annotate(\"label\", x=Inf, y=Inf, vjust=1, hjust=1, size=7,\n",
    "              label=paste(\"Wilcoxon p-adj=\",format(wilcox_clr[wilcox_clr$taxa==mostsign_clr,]$p_adj, scientific=T)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cca87",
   "metadata": {},
   "source": [
    "## DESeq2\n",
    "\n",
    "For deseq2, it makes sense to plot the foldchange together with basemean, as we have obtained these values directly in our results table. Significance can then be made visible in the plot using color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b646d4",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 8, repr.plot.res = 100) #Set the plot size\n",
    "\n",
    "#Plot\n",
    "ggplot(res.df.to.plot, aes(x = log2FoldChange, y = Taxa, col = padj<=0.01)) +\n",
    "  geom_point(aes(size = baseMean))  +\n",
    "  geom_vline(xintercept = 0) +\n",
    "  theme(text = element_text(size=18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb9d8a",
   "metadata": {},
   "source": [
    "However, there are other ways to visualize such a foldchange in the RNAseq field. One method is the volcano plot. When many variables are tested, the shape of a volcano is usually created by this visualisation style, hence the name of the plot. The plot shows the foldchange on one axis and the p-value on the other. DESeq2 results can also be visualized like this quite easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76355d76",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "EnhancedVolcano::EnhancedVolcano(res.df,\n",
    "    lab = res.df$row,\n",
    "    x = 'log2FoldChange',\n",
    "    y = 'pvalue',\n",
    "    title = element_blank(),\n",
    "    FCcutoff = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3090976",
   "metadata": {},
   "source": [
    "## MaAsLin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e8b44",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sig_res_fit <- fit_data$results %>% \n",
    "  filter(qval <= 0.25)  %>%\n",
    "  mutate(feature=factor(feature, levels=feature))\n",
    "sig_res_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b30706",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Task** All that's missing now is some visualization for Maaslin2. You should now be capable of making your own ggplot. Can you think of the best way to display such results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698cf88",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Are the plots really missing? Have a look in the folder ~/kmc_workshop/maaslin2_outputs to see if you can already find plots there. \n",
    "\n",
    "Of course, you can also use a boxplot analogous to Wilcoxon's visualization, in which we display the statistical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ecfd3",
   "metadata": {
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mostsign_maaslin <- sig_res_fit %>%\n",
    "                    arrange(qval) %>%\n",
    "                    pull(feature) %>% # Store the name of most significant taxa\n",
    "                    .[1] %>% # Take the first value\n",
    "                    as.character()\n",
    "mostsign_maaslin\n",
    "\n",
    "\n",
    "ps_filtered %>% \n",
    "    otu_table() %>% \n",
    "    t() %>% # transpose the otu_table\n",
    "    as.data.frame() %>%\n",
    "    mutate(grouping=sample_data(ps_filtered)$lifestyle) %>% #add feature column to our dataframe\n",
    "    select(counts=matches(mostsign_maaslin %>% as.character()), \"grouping\") %>% #replace mostsign_rare with a taxa you would like to plot\n",
    "    ggplot(.,aes(x=grouping, y=counts, fill=grouping))+\n",
    "    geom_boxplot()+ #make a simple boxplot\n",
    "    geom_jitter()+ #add jittered points to the plots\n",
    "    #stat_compare_means(method = \"wilcox.test\")+\n",
    "    theme(text = element_text(size=28))+ # increase text size\n",
    "    ylab(paste0(\"Abundance of \", mostsign_maaslin )) + #Add y axis label\n",
    "    xlab(element_blank())+ #Keep x axis label blank\n",
    "    annotate(\"label\", x=Inf, y=Inf, vjust=1, hjust=1, size=7,\n",
    "              label=paste(\"qval=\",format(sig_res_fit[sig_res_fit$feature==mostsign_maaslin,]$qval, scientific=T)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f7db8",
   "metadata": {},
   "source": [
    "# Result Comparison between Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cdc437",
   "metadata": {},
   "source": [
    "Finally, let's compare the p-values of the three methods. To do this, we need to create a table in which we enter the adjusted p-values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc5723",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pvalue_df <- wilcox_clr %>% select(taxa, wilcox_padj=p_adj) %>% #Wilcoxon table\n",
    "    merge(.,\n",
    "        res.df.to.plot %>% select(taxa=row, deseq_padj=padj), # DESeq2 Results table\n",
    "          by=\"taxa\", all.x=T, all.y=T) %>% \n",
    "    mutate(taxa=str_trim(taxa)) %>%\n",
    "    merge(.,\n",
    "        sig_res_fit %>% # Maaslin2 table\n",
    "        select(taxa=feature, maaslin_padj=qval) %>% \n",
    "         mutate(taxa=as.character(taxa)), \n",
    "         by=\"taxa\", all.x=T, all.y=T) %>% \n",
    "    replace(is.na(.), 1) # Fill NA values with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d12e0",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pvalue_df %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30884c35",
   "metadata": {},
   "source": [
    "We can now create two plots and simply plot the p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd0ce5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_plot_one <- ggplot(pvalue_df, aes(x = deseq_padj, y = wilcox_padj)) +\n",
    "       labs(x = \"DESeq2 adjusted p-value\", y = \"Wilcoxon test adjusted p-value\") +\n",
    "       geom_count() +\n",
    "       scale_size_area(max_size = 10) +\n",
    "       theme(text = element_text(size=18))\n",
    "\n",
    "compare_plot_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1325f8",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_plot_two <- ggplot(pvalue_df, aes(x = deseq_padj, y = maaslin_padj)) +\n",
    "       labs(x = \"DESeq2 adjusted p-value\", y = \"MaAsLin2 adjusted p-value\") +\n",
    "       geom_count() +\n",
    "       scale_size_area(max_size = 10) +\n",
    "       theme(text = element_text(size=18))\n",
    "\n",
    "compare_plot_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c897b",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK** Could you improve the above plots by applying logarithmic scaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a1399",
   "metadata": {
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare_plot_two + scale_y_continuous(trans='log10') + scale_x_continuous(trans='log10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63690a2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(paste0(\"Wilcoxon test p-values under 0.05: \", sum(pvalue_df$wilcox_padj<0.05, na.rm = TRUE), \"/\", length(pvalue_df$wilcox_padj)))\n",
    "print(paste0(\"DESeq2 p-values under 0.05: \", sum(pvalue_df$deseq_padj<0.05, na.rm = TRUE), \"/\", length(pvalue_df$deseq_padj)))\n",
    "print(paste0(\"MaAsLin2 p-values under 0.05: \", sum(pvalue_df$maaslin_padj<0.05, na.rm = TRUE), \"/\", length(pvalue_df$maaslin_padj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88de47",
   "metadata": {},
   "source": [
    "**TASK** Which method provides the most significant taxa and which tool would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e7c37",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK for when you have time:** Can you perform the Wilcoxon test on the rarefied count data similar as for the CLR transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4483d9",
   "metadata": {
    "scrolled": false,
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#rare_members(subset.ps)\n",
    "wilcox_rare <- ps_filtered %>%\n",
    "    rarefy_even_depth(rngseed = 123) %>% # Perform rarefication\n",
    "    otu_table() %>% \n",
    "    t() %>% # transpose the otu_table\n",
    "    as.data.frame() %>%\n",
    "    mutate(grouping=sample_data(ps_filtered)$country)    %>%\n",
    "    rownames_to_column(\"sample_id\") %>%\n",
    "    pivot_longer(cols = c(-sample_id,-grouping), names_to = \"taxa\", values_to = \"abundance\") %>%\n",
    "    group_by(taxa) %>%\n",
    "    summarize(\n",
    "        p_value = wilcox.test(abundance[grouping == chosen_countries[1]], abundance[grouping == chosen_countries[2]])$p.value,\n",
    "        countryone_mean=(mean(abundance[grouping == chosen_countries[1]])),\n",
    "        countrytwo_mean=(mean(abundance[grouping == chosen_countries[2]]))\n",
    "    ) %>%\n",
    "    # Adjust p-values with Bonferroni correction\n",
    "    mutate(p_adj = p.adjust(p_value, method = \"bonferroni\"), .before = countryone_mean) %>%\n",
    "    arrange(p_adj)\n",
    "\n",
    "wilcox_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3983209",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**TASK for when you have time:** Can you plot the Wilcoxon test results based on rarefied count data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1759e",
   "metadata": {
    "solution2": "hidden",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 8, repr.plot.res = 100) #Set the plot size\n",
    "\n",
    "mostsign_rare <- wilcox_clr %>%\n",
    "                    arrange(p_adj) %>%\n",
    "                    pull(taxa) %>% # Store the name of most significant taxa\n",
    "                    .[1] # Take the first value\n",
    "mostsign_rare\n",
    "\n",
    "tansf.df %>% \n",
    "    select(counts=matches(mostsign_clr), \"grouping\") %>% #replace mostsign_clr with a taxa you would like to plot\n",
    "    ggplot(.,aes(x=grouping, y=counts))+\n",
    "    geom_boxplot()+ #make a simple boxplot\n",
    "    geom_jitter()+ #add jittered points to the plots\n",
    "    #stat_compare_means(method = \"wilcox.test\")+\n",
    "    theme(text = element_text(size=28))+\n",
    "    ylab(paste0(\"Abundance of \", mostsign_clr )) +\n",
    "    xlab(element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f07fcb",
   "metadata": {},
   "source": [
    "What difference can you observe between the different statistical results based on the rarefied and CLR transformed data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmc_workshop",
   "language": "R",
   "name": "kmc_workshop"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
